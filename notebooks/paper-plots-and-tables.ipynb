{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a436d249-9dfc-4d25-9695-549cb440ea18",
   "metadata": {},
   "source": [
    "# Render paper plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7df2c18-8ad5-4733-b77e-68afde7064a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247e64e-8d4c-4dc7-beb2-cf70e1492fc2",
   "metadata": {},
   "source": [
    "Load aggregated results data\n",
    "(can be obtained using the `parse-acs-results.ipynb` notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4d0fde-5cea-4ed8-b496-00627aac840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACS_AGG_RESULTS_PATH = Path(\"/fast/groups/sf/folktexts-results\") / \"2024-06-30\" / \"aggregated_results.2024.07.02-12.06.37.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc248c4-a5c5-4c95-9f2a-3d386c830520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_diff</th>\n",
       "      <th>accuracy_ratio</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>balanced_accuracy_diff</th>\n",
       "      <th>balanced_accuracy_ratio</th>\n",
       "      <th>brier_score_loss</th>\n",
       "      <th>ece</th>\n",
       "      <th>ece_quantile</th>\n",
       "      <th>equalized_odds_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>is_inst</th>\n",
       "      <th>num_features</th>\n",
       "      <th>uses_all_features</th>\n",
       "      <th>fit_thresh_on_100</th>\n",
       "      <th>fit_thresh_accuracy</th>\n",
       "      <th>optimal_thresh</th>\n",
       "      <th>optimal_thresh_accuracy</th>\n",
       "      <th>score_stdev</th>\n",
       "      <th>score_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1</th>\n",
       "      <td>0.701552</td>\n",
       "      <td>0.245193</td>\n",
       "      <td>0.679916</td>\n",
       "      <td>0.500011</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.997869</td>\n",
       "      <td>0.298334</td>\n",
       "      <td>0.298337</td>\n",
       "      <td>0.298295</td>\n",
       "      <td>0.001733</td>\n",
       "      <td>...</td>\n",
       "      <td>Mistral 7B (it)</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.678052</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.693145</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta-Llama-3-8B__ACSPublicCoverage__-1</th>\n",
       "      <td>0.298439</td>\n",
       "      <td>0.245500</td>\n",
       "      <td>0.487652</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377804</td>\n",
       "      <td>0.411637</td>\n",
       "      <td>0.411637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Llama 3 8B</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.754837</td>\n",
       "      <td>0.700375</td>\n",
       "      <td>0.718565</td>\n",
       "      <td>0.562519</td>\n",
       "      <td>0.022004</td>\n",
       "      <td>0.710076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 accuracy  accuracy_diff  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1  0.701552       0.245193   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1           0.298439       0.245500   \n",
       "\n",
       "                                                 accuracy_ratio  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1        0.679916   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                 0.487652   \n",
       "\n",
       "                                                 balanced_accuracy  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1           0.500011   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                    0.500000   \n",
       "\n",
       "                                                 balanced_accuracy_diff  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1                0.001067   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                         0.000000   \n",
       "\n",
       "                                                 balanced_accuracy_ratio  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1                 0.997869   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                          1.000000   \n",
       "\n",
       "                                                 brier_score_loss       ece  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1          0.298334  0.298337   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                   0.377804  0.411637   \n",
       "\n",
       "                                                 ece_quantile  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1      0.298295   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1               0.411637   \n",
       "\n",
       "                                                 equalized_odds_diff  ...  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1             0.001733  ...   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                      0.000000  ...   \n",
       "\n",
       "                                                            name  is_inst  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1  Mistral 7B (it)     True   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                Llama 3 8B    False   \n",
       "\n",
       "                                                 num_features  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1            -1   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                     -1   \n",
       "\n",
       "                                                 uses_all_features  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1               True   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                        True   \n",
       "\n",
       "                                                 fit_thresh_on_100  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1           0.000010   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                    0.754837   \n",
       "\n",
       "                                                 fit_thresh_accuracy  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1             0.678052   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                      0.700375   \n",
       "\n",
       "                                                 optimal_thresh  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1        0.000011   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                 0.718565   \n",
       "\n",
       "                                                 optimal_thresh_accuracy  \\\n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1                 0.693145   \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1                          0.562519   \n",
       "\n",
       "                                                score_stdev  score_mean  \n",
       "Mistral-7B-Instruct-v0.2__ACSPublicCoverage__-1    0.006395    0.000144  \n",
       "Meta-Llama-3-8B__ACSPublicCoverage__-1             0.022004    0.710076  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(ACS_AGG_RESULTS_PATH, index_col=0)\n",
    "results_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658cc4b-e0b0-4dd0-a4c6-00c5ed79d4bf",
   "metadata": {},
   "source": [
    "### Run baseline ML classifiers on the benchmark ACS tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f02d293-7725-4754-bce8-caa40c93a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/fast/groups/sf\") / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5299d2a9-3723-44cc-a88b-fbba1d631eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TASKS = [\n",
    "    \"ACSIncome\",\n",
    "    \"ACSMobility\",\n",
    "    \"ACSEmployment\",\n",
    "    \"ACSTravelTime\",\n",
    "    \"ACSPublicCoverage\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b72e20-a5d6-442b-8ba9-f7402f87b77b",
   "metadata": {},
   "source": [
    "List all baseline classifiers here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1749fee2-ea21-41e9-b7f0-9ae5d0868409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier    # NOTE: comment if xgboost is not installed\n",
    "\n",
    "baselines = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"GBM\": HistGradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72fb9307-a5c1-4805-8656-cc352cc736d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktexts.acs.acs_dataset import ACSDataset\n",
    "from folktexts.evaluation import evaluate_predictions\n",
    "from collections import defaultdict\n",
    "\n",
    "def fit_and_eval(\n",
    "    clf,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test, s_test,\n",
    "    fillna=False,\n",
    ") -> dict:\n",
    "    \"\"\"Fit and evaluate a given classifier on the given data.\"\"\"\n",
    "    assert len(X_train) == len(y_train) and len(X_test) == len(y_test) == len(s_test)\n",
    "\n",
    "    train_nan_count = X_train.isna().any(axis=1).sum()\n",
    "    if fillna and train_nan_count > 0:\n",
    "        # Fill NaNs with value=-1\n",
    "        X_train = X_train.fillna(axis=\"columns\", value=-1)\n",
    "        X_test = X_test.fillna(axis=\"columns\", value=-1)\n",
    "\n",
    "    # Fit on train data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_test_scores = clf.predict_proba(X_test)[:, -1]\n",
    "    return evaluate_predictions(\n",
    "        y_true=y_test.to_numpy(),\n",
    "        y_pred_scores=y_test_scores,\n",
    "        sensitive_attribute=s_test,\n",
    "        threshold=0.5,\n",
    "    )\n",
    "\n",
    "def run_baselines(baselines, tasks) -> dict:\n",
    "    \"\"\"Run baseline classifiers on all acs tasks.\"\"\"\n",
    "    baseline_results = defaultdict(dict)\n",
    "\n",
    "    # Prepare progress bar\n",
    "    progress_bar = tqdm(\n",
    "        total=len(tasks) * len(baselines),\n",
    "        leave=True,\n",
    "    )\n",
    "\n",
    "    for task in tasks:\n",
    "        progress_bar.set_postfix({\"task\": task})\n",
    "\n",
    "        # Load ACS task data\n",
    "        acs_dataset = ACSDataset.make_from_task(task=task, cache_dir=DATA_DIR)\n",
    "    \n",
    "        # Get train/test data\n",
    "        X_train, y_train = acs_dataset.get_train()\n",
    "        X_test, y_test = acs_dataset.get_test()\n",
    "    \n",
    "        # Get sensitive attribute test data\n",
    "        s_test = None\n",
    "        if acs_dataset.task.sensitive_attribute is not None:\n",
    "            s_test = acs_dataset.get_sensitive_attribute_data().loc[y_test.index]\n",
    "    \n",
    "        for clf_name, clf in baselines.items():\n",
    "            progress_bar.set_postfix({\"task\": task, \"clf\": clf_name})\n",
    "\n",
    "            try:\n",
    "                baseline_results[task][clf_name] = fit_and_eval(\n",
    "                    clf=clf,\n",
    "                    X_train=X_train, y_train=y_train,\n",
    "                    X_test=X_test, y_test=y_test, s_test=s_test,\n",
    "                    fillna=(clf_name == \"LR\"),\n",
    "                )\n",
    "            except Exception as err:\n",
    "                logging.error(err)\n",
    "            finally:\n",
    "                progress_bar.update()\n",
    "\n",
    "    return baseline_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359a7a3-af13-4516-a07f-7d09f71f99ac",
   "metadata": {},
   "source": [
    "Flatten results and add extra columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4580a3a8-279d-4286-a8d0-01d228b0d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_baseline_results(baseline_results) -> list:\n",
    "    \"\"\"Flatten and parse baseline results.\"\"\"\n",
    "    parsed_results_list = list()\n",
    "    \n",
    "    for task, task_results in baseline_results.items():\n",
    "    \n",
    "        for clf, clf_results in task_results.items():\n",
    "            parsed_results = clf_results.copy()\n",
    "    \n",
    "            parsed_results[\"config_task_name\"] = task\n",
    "            parsed_results[\"config_model_name\"] = clf\n",
    "            parsed_results[\"name\"] = clf\n",
    "            parsed_results[\"num_features\"] = -1\n",
    "            parsed_results[\"uses_all_features\"] = True\n",
    "    \n",
    "            parsed_results_list.append(parsed_results)\n",
    "\n",
    "    return parsed_results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0dd85-79f0-4a6b-a2e1-72fbeb84d85a",
   "metadata": {},
   "source": [
    "Check if baseline results were already computed. If so, load csv; otherwise, compute and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04b361c-780c-4e04-a817-6b2409db84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-computed baseline results from /fast/groups/sf/folktexts-results/2024-06-30/baseline-results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>n_samples</th>\n",
       "      <th>n_positives</th>\n",
       "      <th>n_negatives</th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>tpr</th>\n",
       "      <th>fnr</th>\n",
       "      <th>fpr</th>\n",
       "      <th>tnr</th>\n",
       "      <th>...</th>\n",
       "      <th>equalized_odds_ratio</th>\n",
       "      <th>equalized_odds_diff</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>ece</th>\n",
       "      <th>ece_quantile</th>\n",
       "      <th>config_task_name</th>\n",
       "      <th>config_model_name</th>\n",
       "      <th>name</th>\n",
       "      <th>num_features</th>\n",
       "      <th>uses_all_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.5</td>\n",
       "      <td>166450</td>\n",
       "      <td>61233</td>\n",
       "      <td>105217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.817309</td>\n",
       "      <td>0.732089</td>\n",
       "      <td>0.267911</td>\n",
       "      <td>0.133096</td>\n",
       "      <td>0.866904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077643</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.894961</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.00362</td>\n",
       "      <td>ACSIncome</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBM</th>\n",
       "      <td>0.5</td>\n",
       "      <td>62094</td>\n",
       "      <td>45648</td>\n",
       "      <td>16446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.763117</td>\n",
       "      <td>0.947774</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>0.250578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280813</td>\n",
       "      <td>0.342357</td>\n",
       "      <td>0.738222</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.00497</td>\n",
       "      <td>ACSMobility</td>\n",
       "      <td>GBM</td>\n",
       "      <td>GBM</td>\n",
       "      <td>-1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         threshold  n_samples  n_positives  n_negatives  model_name  accuracy  \\\n",
       "XGBoost        0.5     166450        61233       105217         NaN  0.817309   \n",
       "GBM            0.5      62094        45648        16446         NaN  0.763117   \n",
       "\n",
       "              tpr       fnr       fpr       tnr  ...  equalized_odds_ratio  \\\n",
       "XGBoost  0.732089  0.267911  0.133096  0.866904  ...              0.077643   \n",
       "GBM      0.947774  0.052226  0.749422  0.250578  ...              0.280813   \n",
       "\n",
       "         equalized_odds_diff   roc_auc       ece  ece_quantile  \\\n",
       "XGBoost             0.519188  0.894961  0.004253       0.00362   \n",
       "GBM                 0.342357  0.738222  0.005408       0.00497   \n",
       "\n",
       "         config_task_name  config_model_name     name  num_features  \\\n",
       "XGBoost         ACSIncome            XGBoost  XGBoost            -1   \n",
       "GBM           ACSMobility                GBM      GBM            -1   \n",
       "\n",
       "         uses_all_features  \n",
       "XGBoost               True  \n",
       "GBM                   True  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_RESULTS_PATH = ACS_AGG_RESULTS_PATH.parent / \"baseline-results.csv\"\n",
    "\n",
    "# If saved results exists: load\n",
    "if BASELINE_RESULTS_PATH.exists():\n",
    "    print(f\"Loading pre-computed baseline results from {BASELINE_RESULTS_PATH.as_posix()}\")\n",
    "    baselines_df = pd.read_csv(BASELINE_RESULTS_PATH, index_col=0)\n",
    "\n",
    "# Compute baseline results\n",
    "else:\n",
    "    # Compute baseline results\n",
    "    baseline_results = run_baselines(baselines, tasks=ALL_TASKS)\n",
    "\n",
    "    # Parse results\n",
    "    parsed_results_list = parse_baseline_results(baseline_results)\n",
    "\n",
    "    # Construct DF\n",
    "    baselines_df = pd.DataFrame(parsed_results_list, index=[r[\"name\"] for r in parsed_results_list])\n",
    "\n",
    "    # Save DF to disk\n",
    "    baselines_df.to_csv(BASELINE_RESULTS_PATH)\n",
    "\n",
    "# Show 2 random rows\n",
    "baselines_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b4ddea-bd88-4bee-87cc-b6aaa6af5630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_results_df.shape=(109, 64)\n"
     ]
    }
   ],
   "source": [
    "all_results_df = pd.concat((results_df, baselines_df))\n",
    "print(f\"{all_results_df.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b657133-120f-4ddb-95ef-b7106b9511fb",
   "metadata": {},
   "source": [
    "## Render results table for each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "317e5744-31e3-48ef-b051-484f79b01a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_metrics = [\"ece\", \"brier_score_loss\", \"roc_auc\", \"accuracy\", \"fit_thresh_accuracy\", \"score_stdev\"] #, \"score_mean\"]\n",
    "\n",
    "model_col = \"config_model_name\"\n",
    "task_col = \"config_task_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df28300-70ee-47d7-b7ad-23d06ed415cc",
   "metadata": {},
   "source": [
    "Add model size and model family columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41009307-905b-4498-b98e-972b589f68ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config_task_name   model_family\n",
       "ACSEmployment      -               3\n",
       "                   Gemma           8\n",
       "                   Llama           4\n",
       "                   Mistral         6\n",
       "                   Yi              1\n",
       "ACSIncome          -               3\n",
       "                   Gemma           7\n",
       "                   Llama           4\n",
       "                   Mistral         6\n",
       "                   Yi              2\n",
       "ACSMobility        -               3\n",
       "                   Gemma           8\n",
       "                   Llama           4\n",
       "                   Mistral         5\n",
       "                   Yi              2\n",
       "ACSPublicCoverage  -               3\n",
       "                   Gemma           8\n",
       "                   Llama           4\n",
       "                   Mistral         5\n",
       "                   Yi              2\n",
       "ACSTravelTime      -               3\n",
       "                   Gemma           8\n",
       "                   Llama           4\n",
       "                   Mistral         4\n",
       "                   Yi              2\n",
       "Name: accuracy, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from folktexts.llm_utils import get_model_size_B\n",
    "\n",
    "all_results_df[\"model_size\"] = [\n",
    "    (\n",
    "        get_model_size_B(row[\"name\"], default=float(\"nan\"))\n",
    "        if row[\"name\"] not in baselines else \"-\"\n",
    "    )\n",
    "    for _, row in all_results_df.iterrows()\n",
    "]\n",
    "\n",
    "def get_model_family(model_name) -> str:\n",
    "    if \"llama\" in model_name.lower():\n",
    "        return \"Llama\"\n",
    "    elif \"mistral\" in model_name.lower() or \"mixtral\" in model_name.lower():\n",
    "        return \"Mistral\"\n",
    "    elif \"gemma\" in model_name.lower():\n",
    "        return \"Gemma\"\n",
    "    elif \"yi\" in model_name.lower():\n",
    "        return \"Yi\"\n",
    "    elif \"qwen\" in model_name.lower():\n",
    "        return \"Qwen\"\n",
    "    else:\n",
    "        return \"-\"\n",
    "\n",
    "all_results_df[\"model_family\"] = [get_model_family(row[model_col]) for _, row in all_results_df.iterrows()]\n",
    "all_results_df.groupby([task_col, \"model_family\"])[\"accuracy\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "477e4f80-2c42-458b-a98c-b32a95c7d67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** ACSINCOME ***\n",
      "\n",
      "\\begin{tabular}{lrrrrll}\n",
      "\\toprule\n",
      " & ece & brier score loss & roc auc & accuracy & fit thresh accuracy & score stdev \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Yi 34B (chat) & 0.19 & 0.19 & 0.86 & 0.72 & 0.76 & 0.34 \\\\\n",
      "Yi 34B & 0.25 & 0.22 & 0.85 & 0.62 & 0.77 & 0.20 \\\\\n",
      "Mixtral 8x22B (it) & 0.21 & 0.22 & 0.85 & 0.76 & 0.75 & 0.48 \\\\\n",
      "Mixtral 8x22B & 0.16 & 0.19 & 0.85 & 0.68 & 0.78 & 0.10 \\\\\n",
      "Mixtral 8x7B (it) & 0.16 & 0.18 & 0.86 & 0.78 & 0.78 & 0.42 \\\\\n",
      "Mixtral 8x7B & 0.17 & 0.21 & 0.83 & 0.65 & 0.74 & 0.06 \\\\\n",
      "Mistral 7B (it) & 0.21 & 0.22 & 0.83 & 0.77 & 0.77 & 0.42 \\\\\n",
      "Mistral 7B & 0.20 & 0.23 & 0.80 & 0.73 & 0.73 & 0.04 \\\\\n",
      "Llama 3 70B (it) & 0.27 & 0.27 & 0.86 & 0.69 & 0.78 & 0.42 \\\\\n",
      "Llama 3 70B & 0.20 & 0.20 & 0.86 & 0.70 & 0.78 & 0.14 \\\\\n",
      "Llama 3 8B (it) & 0.32 & 0.30 & 0.85 & 0.62 & 0.77 & 0.37 \\\\\n",
      "Llama 3 8B & 0.25 & 0.26 & 0.81 & 0.38 & 0.69 & 0.05 \\\\\n",
      "Gemma 2 27B (it) & 0.34 & 0.35 & 0.71 & 0.57 & 0.67 & 0.36 \\\\\n",
      "Gemma 2 9B (it) & 0.20 & 0.20 & 0.84 & 0.78 & 0.78 & 0.45 \\\\\n",
      "Gemma 2 9B & 0.26 & 0.25 & 0.83 & 0.40 & 0.72 & 0.06 \\\\\n",
      "Gemma 7B (it) & 0.61 & 0.59 & 0.84 & 0.37 & 0.70 & 0.06 \\\\\n",
      "Gemma 7B & 0.24 & 0.27 & 0.76 & 0.37 & 0.69 & 0.04 \\\\\n",
      "Gemma 2B (it) & 0.63 & 0.63 & 0.73 & 0.37 & 0.63 & 0.00 \\\\\n",
      "Gemma 2B & 0.14 & 0.25 & 0.62 & 0.45 & 0.63 & 0.02 \\\\\n",
      "LR & 0.03 & 0.18 & 0.79 & 0.74 & - & - \\\\\n",
      "GBM & 0.01 & 0.13 & 0.89 & 0.81 & - & - \\\\\n",
      "XGBoost & 0.00 & 0.13 & 0.90 & 0.82 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "*** ACSMOBILITY ***\n",
      "\n",
      "\\begin{tabular}{lrrrrll}\n",
      "\\toprule\n",
      " & ece & brier score loss & roc auc & accuracy & fit thresh accuracy & score stdev \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Yi 34B (chat) & 0.09 & 0.20 & 0.56 & 0.72 & 0.61 & 0.15 \\\\\n",
      "Yi 34B & 0.07 & 0.20 & 0.57 & 0.73 & 0.61 & 0.08 \\\\\n",
      "Mixtral 8x22B & 0.11 & 0.20 & 0.56 & 0.73 & 0.47 & 0.02 \\\\\n",
      "Mixtral 8x7B (it) & 0.26 & 0.26 & 0.58 & 0.73 & 0.62 & 0.02 \\\\\n",
      "Mixtral 8x7B & 0.14 & 0.21 & 0.57 & 0.73 & 0.52 & 0.03 \\\\\n",
      "Mistral 7B (it) & 0.26 & 0.26 & 0.57 & 0.73 & 0.54 & 0.02 \\\\\n",
      "Mistral 7B & 0.20 & 0.23 & 0.53 & 0.73 & 0.58 & 0.01 \\\\\n",
      "Llama 3 70B (it) & 0.20 & 0.25 & 0.57 & 0.61 & 0.48 & 0.18 \\\\\n",
      "Llama 3 70B & 0.22 & 0.24 & 0.55 & 0.67 & 0.53 & 0.04 \\\\\n",
      "Llama 3 8B (it) & 0.15 & 0.22 & 0.56 & 0.70 & 0.53 & 0.17 \\\\\n",
      "Llama 3 8B & 0.10 & 0.20 & 0.55 & 0.73 & 0.49 & 0.04 \\\\\n",
      "Gemma 2 27B (it) & 0.40 & 0.40 & 0.52 & 0.45 & 0.58 & 0.33 \\\\\n",
      "Gemma 2 27B & 0.23 & 0.28 & 0.49 & 0.61 & 0.54 & 0.27 \\\\\n",
      "Gemma 2 9B (it) & 0.20 & 0.23 & 0.54 & 0.73 & 0.67 & 0.07 \\\\\n",
      "Gemma 2 9B & 0.31 & 0.29 & 0.54 & 0.29 & 0.40 & 0.04 \\\\\n",
      "Gemma 7B (it) & 0.25 & 0.26 & 0.58 & 0.73 & 0.67 & 0.11 \\\\\n",
      "Gemma 7B & 0.41 & 0.37 & 0.50 & 0.39 & 0.51 & 0.10 \\\\\n",
      "Gemma 2B (it) & 0.73 & 0.73 & 0.52 & 0.27 & 0.40 & 0.00 \\\\\n",
      "Gemma 2B & 0.25 & 0.26 & 0.51 & 0.40 & 0.48 & 0.02 \\\\\n",
      "LR & 0.02 & 0.19 & 0.61 & 0.74 & - & - \\\\\n",
      "GBM & 0.01 & 0.17 & 0.74 & 0.76 & - & - \\\\\n",
      "XGBoost & 0.00 & 0.16 & 0.74 & 0.76 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "*** ACSEMPLOYMENT ***\n",
      "\n",
      "\\begin{tabular}{lrrrrll}\n",
      "\\toprule\n",
      " & ece & brier score loss & roc auc & accuracy & fit thresh accuracy & score stdev \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Yi 34B (chat) & 0.14 & 0.21 & 0.79 & 0.69 & 0.73 & 0.20 \\\\\n",
      "Mixtral 8x22B (it) & 0.38 & 0.39 & 0.60 & 0.51 & 0.60 & 0.27 \\\\\n",
      "Mixtral 8x22B & 0.21 & 0.24 & 0.86 & 0.52 & 0.77 & 0.08 \\\\\n",
      "Mixtral 8x7B (it) & 0.22 & 0.24 & 0.82 & 0.73 & 0.75 & 0.44 \\\\\n",
      "Mixtral 8x7B & 0.29 & 0.31 & 0.81 & 0.45 & 0.74 & 0.06 \\\\\n",
      "Mistral 7B (it) & 0.35 & 0.36 & 0.72 & 0.63 & 0.66 & 0.49 \\\\\n",
      "Mistral 7B & 0.26 & 0.30 & 0.76 & 0.45 & 0.69 & 0.04 \\\\\n",
      "Llama 3 70B (it) & 0.17 & 0.19 & 0.85 & 0.73 & 0.78 & 0.29 \\\\\n",
      "Llama 3 70B & 0.25 & 0.26 & 0.82 & 0.52 & 0.74 & 0.12 \\\\\n",
      "Llama 3 8B (it) & 0.07 & 0.19 & 0.79 & 0.74 & 0.73 & 0.22 \\\\\n",
      "Llama 3 8B & 0.34 & 0.34 & 0.76 & 0.45 & 0.69 & 0.06 \\\\\n",
      "Gemma 2 27B (it) & 0.31 & 0.36 & 0.51 & 0.52 & 0.53 & 0.35 \\\\\n",
      "Gemma 2 27B & 0.26 & 0.34 & 0.50 & 0.49 & 0.52 & 0.27 \\\\\n",
      "Gemma 2 9B (it) & 0.16 & 0.20 & 0.82 & 0.70 & 0.74 & 0.25 \\\\\n",
      "Gemma 2 9B & 0.13 & 0.24 & 0.73 & 0.52 & 0.67 & 0.07 \\\\\n",
      "Gemma 7B (it) & 0.36 & 0.38 & 0.59 & 0.58 & 0.59 & 0.44 \\\\\n",
      "Gemma 7B & 0.15 & 0.25 & 0.65 & 0.48 & 0.63 & 0.13 \\\\\n",
      "Gemma 2B (it) & 0.38 & 0.41 & 0.42 & 0.46 & 0.48 & 0.23 \\\\\n",
      "Gemma 2B & 0.01 & 0.24 & 0.63 & 0.54 & 0.61 & 0.03 \\\\\n",
      "LR & 0.02 & 0.15 & 0.86 & 0.78 & - & - \\\\\n",
      "GBM & 0.00 & 0.12 & 0.91 & 0.83 & - & - \\\\\n",
      "XGBoost & 0.00 & 0.12 & 0.91 & 0.83 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "*** ACSTRAVELTIME ***\n",
      "\n",
      "\\begin{tabular}{lrrrrll}\n",
      "\\toprule\n",
      " & ece & brier score loss & roc auc & accuracy & fit thresh accuracy & score stdev \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Yi 34B (chat) & 0.35 & 0.36 & 0.65 & 0.56 & 0.52 & 0.02 \\\\\n",
      "Yi 34B & 0.08 & 0.24 & 0.62 & 0.56 & 0.54 & 0.06 \\\\\n",
      "Mixtral 8x7B (it) & 0.45 & 0.45 & 0.66 & 0.52 & 0.55 & 0.29 \\\\\n",
      "Mixtral 8x7B & 0.28 & 0.32 & 0.60 & 0.44 & 0.56 & 0.03 \\\\\n",
      "Mistral 7B (it) & 0.41 & 0.42 & 0.59 & 0.57 & 0.53 & 0.19 \\\\\n",
      "Mistral 7B & 0.05 & 0.25 & 0.57 & 0.56 & 0.55 & 0.02 \\\\\n",
      "Llama 3 70B (it) & 0.15 & 0.24 & 0.70 & 0.60 & 0.61 & 0.12 \\\\\n",
      "Llama 3 70B & 0.09 & 0.24 & 0.67 & 0.55 & 0.61 & 0.05 \\\\\n",
      "Llama 3 8B (it) & 0.19 & 0.28 & 0.60 & 0.57 & 0.55 & 0.11 \\\\\n",
      "Llama 3 8B & 0.08 & 0.25 & 0.53 & 0.56 & 0.54 & 0.03 \\\\\n",
      "Gemma 2 27B (it) & 0.32 & 0.36 & 0.52 & 0.53 & 0.48 & 0.34 \\\\\n",
      "Gemma 2 27B & 0.23 & 0.32 & 0.50 & 0.49 & 0.46 & 0.25 \\\\\n",
      "Gemma 2 9B (it) & 0.07 & 0.23 & 0.67 & 0.60 & 0.57 & 0.15 \\\\\n",
      "Gemma 2 9B & 0.02 & 0.24 & 0.58 & 0.56 & 0.51 & 0.02 \\\\\n",
      "Gemma 7B (it) & 0.42 & 0.43 & 0.53 & 0.56 & 0.52 & 0.02 \\\\\n",
      "Gemma 7B & 0.04 & 0.24 & 0.61 & 0.58 & 0.57 & 0.02 \\\\\n",
      "Gemma 2B (it) & 0.34 & 0.36 & 0.49 & 0.56 & 0.54 & 0.03 \\\\\n",
      "Gemma 2B & 0.09 & 0.26 & 0.48 & 0.44 & 0.54 & 0.01 \\\\\n",
      "LR & 0.04 & 0.24 & 0.58 & 0.56 & - & - \\\\\n",
      "GBM & 0.02 & 0.20 & 0.75 & 0.69 & - & - \\\\\n",
      "XGBoost & 0.02 & 0.19 & 0.77 & 0.70 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "*** ACSPUBLICCOVERAGE ***\n",
      "\n",
      "\\begin{tabular}{lrrrrll}\n",
      "\\toprule\n",
      " & ece & brier score loss & roc auc & accuracy & fit thresh accuracy & score stdev \\\\\n",
      "Model &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "Yi 34B (chat) & 0.06 & 0.19 & 0.67 & 0.74 & 0.70 & 0.13 \\\\\n",
      "Yi 34B & 0.04 & 0.21 & 0.59 & 0.70 & 0.32 & 0.07 \\\\\n",
      "Mixtral 8x22B & 0.32 & 0.30 & 0.59 & 0.30 & 0.53 & 0.05 \\\\\n",
      "Mixtral 8x7B (it) & 0.20 & 0.23 & 0.70 & 0.74 & 0.72 & 0.35 \\\\\n",
      "Mixtral 8x7B & 0.41 & 0.37 & 0.57 & 0.30 & 0.38 & 0.03 \\\\\n",
      "Mistral 7B (it) & 0.30 & 0.30 & 0.61 & 0.70 & 0.68 & 0.01 \\\\\n",
      "Mistral 7B & 0.29 & 0.30 & 0.45 & 0.30 & 0.70 & 0.02 \\\\\n",
      "Llama 3 70B (it) & 0.16 & 0.21 & 0.69 & 0.75 & 0.49 & 0.20 \\\\\n",
      "Llama 3 70B & 0.18 & 0.22 & 0.67 & 0.63 & 0.50 & 0.07 \\\\\n",
      "Llama 3 8B (it) & 0.11 & 0.21 & 0.59 & 0.71 & 0.72 & 0.19 \\\\\n",
      "Llama 3 8B & 0.41 & 0.38 & 0.55 & 0.30 & 0.70 & 0.02 \\\\\n",
      "Gemma 2 27B (it) & 0.24 & 0.29 & 0.54 & 0.63 & 0.57 & 0.30 \\\\\n",
      "Gemma 2 27B & 0.43 & 0.43 & 0.51 & 0.38 & 0.52 & 0.24 \\\\\n",
      "Gemma 2 9B (it) & 0.16 & 0.23 & 0.61 & 0.67 & 0.68 & 0.28 \\\\\n",
      "Gemma 2 9B & 0.20 & 0.25 & 0.50 & 0.38 & 0.65 & 0.02 \\\\\n",
      "Gemma 7B (it) & 0.30 & 0.34 & 0.46 & 0.50 & 0.32 & 0.32 \\\\\n",
      "Gemma 7B & 0.15 & 0.23 & 0.49 & 0.49 & 0.37 & 0.10 \\\\\n",
      "Gemma 2B (it) & 0.70 & 0.70 & 0.54 & 0.30 & 0.33 & 0.00 \\\\\n",
      "Gemma 2B & 0.26 & 0.28 & 0.54 & 0.30 & 0.62 & 0.01 \\\\\n",
      "LR & 0.03 & 0.19 & 0.70 & 0.73 & - & - \\\\\n",
      "GBM & 0.01 & 0.14 & 0.83 & 0.80 & - & - \\\\\n",
      "XGBoost & 0.00 & 0.14 & 0.84 & 0.80 & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import prettify_model_name\n",
    "\n",
    "for task in ALL_TASKS:\n",
    "    task_df = all_results_df[all_results_df[task_col] == task]\n",
    "\n",
    "    latex_table = task_df.sort_values([\"model_family\", \"model_size\", \"is_inst\"], ascending=False).set_index(model_col)[table_metrics].round(3)\n",
    "    latex_table = latex_table.rename(columns=lambda col: col.replace(\"_\", \" \")).fillna(\"-\")\n",
    "\n",
    "    # Prettify model names\n",
    "    latex_table[\"Model\"] = [\n",
    "        prettify_model_name(id_) if id_ not in baselines.keys() else id_\n",
    "        for id_, row in latex_table.iterrows()\n",
    "    ]\n",
    "    latex_table.set_index(\"Model\", drop=True, inplace=True)\n",
    "\n",
    "    print(f\"*** {task.upper()} ***\\n\")\n",
    "    print(latex_table.to_latex(float_format=\"%.2f\"))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4564ed-1e41-4322-8c87-74fc34265bf5",
   "metadata": {},
   "source": [
    "## Render plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8819b1-0033-4d44-ab1e-a4b55a4ebd65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
